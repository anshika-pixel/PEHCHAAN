{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d060a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import python_speech_features as mfcc\n",
    "\n",
    "def calculate_delta(array):\n",
    "    \"\"\"Calculate and returns the delta of given feature vector matrix\"\"\"\n",
    "\n",
    "    rows,cols = array.shape\n",
    "    deltas = np.zeros((rows,20))\n",
    "    N = 2\n",
    "    for i in range(rows):\n",
    "        index = []\n",
    "        j = 1\n",
    "        while j <= N:\n",
    "            if i-j < 0:\n",
    "              first =0\n",
    "            else:\n",
    "              first = i-j\n",
    "            if i+j > rows-1:\n",
    "                second = rows-1\n",
    "            else:\n",
    "                second = i+j \n",
    "            index.append((second,first))\n",
    "            j+=1\n",
    "        deltas[i] = ( array[index[0][0]]-array[index[0][1]] + (2 * (array[index[1][0]]-array[index[1][1]])) ) / 10\n",
    "    return deltas\n",
    "\n",
    "def extract_features(audio,rate):\n",
    "    \"\"\"extract 20 dim mfcc features from an audio, performs CMS and combines \n",
    "    delta to make it 40 dim feature vector\"\"\"    \n",
    "    \n",
    "    mfcc_feature = mfcc.mfcc(audio,rate, 0.025, 0.01,20,nfft = 1200, appendEnergy = True)    \n",
    "    mfcc_feature = preprocessing.scale(mfcc_feature)\n",
    "    delta = calculate_delta(mfcc_feature)\n",
    "    combined = np.hstack((mfcc_feature,delta)) \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed5fe58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1e6001e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aashna Hegde/AH1(1).wav\n",
      "Aashna Hegde/AH1(2).wav\n",
      "Aashna Hegde/AH2(1).wav\n",
      "Aashna Hegde/AH2(2).wav\n",
      "Aashna Hegde/AH3(1).wav\n",
      "+ modeling completed for speaker: Aashna Hegde/AH3(1).wav.gmm  with data point =  (61321, 40)\n",
      "Ashish/Ashish1(1).wav\n",
      "Ashish/Ashish1(2).wav\n",
      "Ashish/Ashish2(1).wav\n",
      "Ashish/Ashish2(2).wav\n",
      "Ashish/Ashish3(1).wav\n",
      "+ modeling completed for speaker: Ashish/Ashish3(1).wav.gmm  with data point =  (60010, 40)\n",
      "BB Ki Vines/BB1(1).wav\n",
      "BB Ki Vines/BB1(2).wav\n",
      "BB Ki Vines/BB2(1).wav\n",
      "BB Ki Vines/BB2(2).wav\n",
      "BB Ki Vines/BB3(1).wav\n",
      "+ modeling completed for speaker: BB Ki Vines/BB3(1).wav.gmm  with data point =  (60010, 40)\n",
      "Beer Biceps/Beer1(1).wav\n",
      "Beer Biceps/Beer1(2).wav\n",
      "Beer Biceps/Beer2(1).wav\n",
      "Beer Biceps/Beer2(2).wav\n",
      "Beer Biceps/Beer3(1).wav\n",
      "+ modeling completed for speaker: Beer Biceps/Beer3(1).wav.gmm  with data point =  (61979, 40)\n",
      "Carryminati/Carryminati1(1).wav\n",
      "Carryminati/Carryminati1(2).wav\n",
      "Carryminati/Carryminati2(1).wav\n",
      "Carryminati/Carryminati2(2).wav\n",
      "Carryminati/Carryminati3(1).wav\n",
      "+ modeling completed for speaker: Carryminati/Carryminati3(1).wav.gmm  with data point =  (60000, 40)\n",
      "Dhruv RATHEE/Dhruv1(1).wav\n",
      "Dhruv RATHEE/Dhruv1(2).wav\n",
      "Dhruv RATHEE/Dhruv2(1).wav\n",
      "Dhruv RATHEE/Dhruv2(2).wav\n",
      "Dhruv RATHEE/Dhruv3(1).wav\n",
      "+ modeling completed for speaker: Dhruv RATHEE/Dhruv3(1).wav.gmm  with data point =  (60010, 40)\n",
      "Flying Beast/FB1(1).wav\n",
      "Flying Beast/FB1(2).wav\n",
      "Flying Beast/FB2(1).wav\n",
      "Flying Beast/FB2(2).wav\n",
      "Flying Beast/FB3(1).wav\n",
      "+ modeling completed for speaker: Flying Beast/FB3(1).wav.gmm  with data point =  (60010, 40)\n",
      "Harsh Beniwal/Harsh1(1).wav\n",
      "Harsh Beniwal/Harsh1(2).wav\n",
      "Harsh Beniwal/Harsh1(3).wav\n",
      "Harsh Beniwal/Harsh2(1).wav\n",
      "Harsh Beniwal/Harsh2(2).wav\n",
      "+ modeling completed for speaker: Harsh Beniwal/Harsh2(2).wav.gmm  with data point =  (60010, 40)\n",
      "Kabita/K1(1).wav\n",
      "Kabita/K1(2).wav\n",
      "Kabita/K1(3).wav\n",
      "Kabita/K2(1).wav\n",
      "Kabita/K2(2).wav\n",
      "+ modeling completed for speaker: Kabita/K2(2).wav.gmm  with data point =  (60728, 40)\n",
      "Kenny Sebastian/KS1(1).wav\n",
      "Kenny Sebastian/KS1(2).wav\n",
      "Kenny Sebastian/KS2(1).wav\n",
      "Kenny Sebastian/KS2(2).wav\n",
      "Kenny Sebastian/KS3(1).wav\n",
      "+ modeling completed for speaker: Kenny Sebastian/KS3(1).wav.gmm  with data point =  (62541, 40)\n",
      "MostlySane/MS1(1).wav\n",
      "MostlySane/MS1(2).wav\n",
      "MostlySane/MS2(1).wav\n",
      "MostlySane/MS2(2).wav\n",
      "MostlySane/MS3(1).wav\n",
      "+ modeling completed for speaker: MostlySane/MS3(1).wav.gmm  with data point =  (61369, 40)\n",
      "Mr. Indian Hacker/IH1(1).wav\n",
      "Mr. Indian Hacker/IH1(2).wav\n",
      "Mr. Indian Hacker/IH2(1).wav\n",
      "Mr. Indian Hacker/IH2(2).wav\n",
      "Mr. Indian Hacker/IH3(1).wav\n",
      "+ modeling completed for speaker: Mr. Indian Hacker/IH3(1).wav.gmm  with data point =  (60548, 40)\n",
      "Sandeep Maheshwari/SM1(1).wav\n",
      "Sandeep Maheshwari/SM1(2).wav\n",
      "Sandeep Maheshwari/SM2(1).wav\n",
      "Sandeep Maheshwari/SM2(2).wav\n",
      "Sandeep Maheshwari/SM3(1).wav\n",
      "+ modeling completed for speaker: Sandeep Maheshwari/SM3(1).wav.gmm  with data point =  (59850, 40)\n",
      "Sejal Kumar/SK1(1).wav\n",
      "Sejal Kumar/SK1(2).wav\n",
      "Sejal Kumar/SK2(1).wav\n",
      "Sejal Kumar/SK2(2).wav\n",
      "Sejal Kumar/SK3(1).wav\n",
      "+ modeling completed for speaker: Sejal Kumar/SK3(1).wav.gmm  with data point =  (61739, 40)\n",
      "Shivani Bafna/SB1(1).wav\n",
      "Shivani Bafna/SB1(2).wav\n",
      "Shivani Bafna/SB2(1).wav\n",
      "Shivani Bafna/SB2(2).wav\n",
      "Shivani Bafna/SB3(1).wav\n",
      "+ modeling completed for speaker: Shivani Bafna/SB3(1).wav.gmm  with data point =  (61272, 40)\n",
      "Yuzi/Yuzi1.wav\n",
      "Yuzi/Yuzi2.wav\n",
      "Yuzi/Yuzi3.wav\n",
      "Yuzi/Yuzi4.wav\n",
      "Yuzi/Yuzi5.wav\n",
      "+ modeling completed for speaker: Yuzi/Yuzi5.wav.gmm  with data point =  (59963, 40)\n",
      "Aakash_chopra/Aakash_Chopra1.wav\n",
      "Aakash_chopra/Aakash_Chopra2.wav\n",
      "Aakash_chopra/Aakash_Chopra3.wav\n",
      "Aakash_chopra/Aakash_Chopra4.wav\n",
      "Aakash_chopra/Aakash_Chopra5.wav\n",
      "+ modeling completed for speaker: Aakash_chopra/Aakash_Chopra5.wav.gmm  with data point =  (60820, 40)\n",
      "ABD/ABD1.wav\n",
      "ABD/ABD2.wav\n",
      "ABD/ABD3.wav\n",
      "ABD/ABD4.wav\n",
      "ABD/ABD5.wav\n",
      "+ modeling completed for speaker: ABD/ABD5.wav.gmm  with data point =  (74523, 40)\n",
      "Ashwin/Ashwin1.wav\n",
      "Ashwin/Ashwin2.wav\n",
      "Ashwin/Ashwin3.wav\n",
      "Ashwin/Ashwin4.wav\n",
      "Ashwin/Ashwin5.wav\n",
      "+ modeling completed for speaker: Ashwin/Ashwin5.wav.gmm  with data point =  (69058, 40)\n",
      "Ben_stokes/Ben_stokes1.wav\n",
      "Ben_stokes/Ben_stokes2.wav\n",
      "Ben_stokes/Ben_stokes3.wav\n",
      "Ben_stokes/Ben_stokes4.wav\n",
      "Ben_stokes/Ben_stokes5.wav\n",
      "+ modeling completed for speaker: Ben_stokes/Ben_stokes5.wav.gmm  with data point =  (64860, 40)\n",
      "Bhuvi/Bhuvi1.wav\n",
      "Bhuvi/Bhuvi2.wav\n",
      "Bhuvi/Bhuvi3.wav\n",
      "Bhuvi/Bhuvi4.wav\n",
      "Bhuvi/Bhuvi5.wav\n",
      "+ modeling completed for speaker: Bhuvi/Bhuvi5.wav.gmm  with data point =  (73149, 40)\n",
      "Bindra/Abhinav_Bindra1.wav\n",
      "Bindra/Abhinav_Bindra2.wav\n",
      "Bindra/Abhinav_Bindra3.wav\n",
      "Bindra/Abhinav_Bindra4.wav\n",
      "Bindra/Abhinav_Bindra5.wav\n",
      "+ modeling completed for speaker: Bindra/Abhinav_Bindra5.wav.gmm  with data point =  (33815, 40)\n",
      "Ganguly/Saurav_Ganguly1.wav\n",
      "Ganguly/Saurav_Ganguly2.wav\n",
      "Ganguly/Saurav_Ganguly3.wav\n",
      "Ganguly/Saurav_Ganguly4.wav\n",
      "Ganguly/Saurav_Ganguly5.wav\n",
      "+ modeling completed for speaker: Ganguly/Saurav_Ganguly5.wav.gmm  with data point =  (98378, 40)\n",
      "Kohli/Virat_kohli1.wav\n",
      "Kohli/Virat_kohli2.wav\n",
      "Kohli/Virat_kohli3.wav\n",
      "Kohli/Virat_kohli4.wav\n",
      "Kohli/Virat_kohli5.wav\n",
      "+ modeling completed for speaker: Kohli/Virat_kohli5.wav.gmm  with data point =  (61836, 40)\n",
      "Raina/Suresh_Raina1.wav\n",
      "Raina/Suresh_Raina2.wav\n",
      "Raina/Suresh_Raina3.wav\n",
      "Raina/Suresh_Raina4.wav\n",
      "Raina/Suresh_Raina5.wav\n",
      "+ modeling completed for speaker: Raina/Suresh_Raina5.wav.gmm  with data point =  (67558, 40)\n",
      "Sachin/Sachin1.wav\n",
      "Sachin/Sachin2.wav\n",
      "Sachin/Sachin3.wav\n",
      "Sachin/Sachin4.wav\n",
      "Sachin/Sachin5.wav\n",
      "+ modeling completed for speaker: Sachin/Sachin5.wav.gmm  with data point =  (61618, 40)\n",
      "Tim_Paine/Tim_Paine1.wav\n",
      "Tim_Paine/Tim_Paine2.wav\n",
      "Tim_Paine/Tim_Paine3.wav\n",
      "Tim_Paine/Tim_Paine4.wav\n",
      "Tim_Paine/Tim_Paine5.wav\n",
      "+ modeling completed for speaker: Tim_Paine/Tim_Paine5.wav.gmm  with data point =  (61270, 40)\n",
      "Deepika_Padukone/DeepikaPadukone1.wav\n",
      "Deepika_Padukone/DeepikaPadukone2.wav\n",
      "Deepika_Padukone/DeepikaPadukone3.wav\n",
      "Deepika_Padukone/DeepikaPadukone4.wav\n",
      "Deepika_Padukone/DeepikaPadukone5.wav\n",
      "+ modeling completed for speaker: Deepika_Padukone/DeepikaPadukone5.wav.gmm  with data point =  (60034, 40)\n",
      "Parineeti_Chopra/ParineetiChopra1.wav\n",
      "Parineeti_Chopra/ParineetiChopra2.wav\n",
      "Parineeti_Chopra/ParineetiChopra3.wav\n",
      "Parineeti_Chopra/ParineetiChopra4.wav\n",
      "Parineeti_Chopra/ParineetiChopra5.wav\n",
      "+ modeling completed for speaker: Parineeti_Chopra/ParineetiChopra5.wav.gmm  with data point =  (60028, 40)\n",
      "Ayushmann_Khurrana/AyushmannKhurrana1.wav\n",
      "Ayushmann_Khurrana/AyushmannKhurrana2.wav\n",
      "Ayushmann_Khurrana/AyushmannKhurrana3.wav\n",
      "Ayushmann_Khurrana/AyushmannKhurrana4.wav\n",
      "Ayushmann_Khurrana/AyushmannKhurrana5.wav\n",
      "+ modeling completed for speaker: Ayushmann_Khurrana/AyushmannKhurrana5.wav.gmm  with data point =  (60028, 40)\n",
      "Kriti_Sanon/KritiSanon1.wav\n",
      "Kriti_Sanon/KritiSanon2.wav\n",
      "Kriti_Sanon/KritiSanon3.wav\n",
      "Kriti_Sanon/KritiSanon4.wav\n",
      "Kriti_Sanon/KritiSanon5.wav\n",
      "+ modeling completed for speaker: Kriti_Sanon/KritiSanon5.wav.gmm  with data point =  (60037, 40)\n",
      "Kartik_Aaryan/KartikAaryan1.wav\n",
      "Kartik_Aaryan/KartikAaryan2.wav\n",
      "Kartik_Aaryan/KartikAaryan3.wav\n",
      "Kartik_Aaryan/KartikAaryan4.wav\n",
      "Kartik_Aaryan/KartikAaryan5.wav\n",
      "+ modeling completed for speaker: Kartik_Aaryan/KartikAaryan5.wav.gmm  with data point =  (60037, 40)\n",
      "Akshay_Kumar/AkshayKumar1.wav\n",
      "Akshay_Kumar/AkshayKumar2.wav\n",
      "Akshay_Kumar/AkshayKumar3.wav\n",
      "Akshay_Kumar/AkshayKumar4.wav\n",
      "Akshay_Kumar/AkshayKumar5.wav\n",
      "+ modeling completed for speaker: Akshay_Kumar/AkshayKumar5.wav.gmm  with data point =  (60040, 40)\n",
      "Anushka_Sharma/AnushkaSharma1.wav\n",
      "Anushka_Sharma/AnushkaSharma2.wav\n",
      "Anushka_Sharma/AnushkaSharma3.wav\n",
      "Anushka_Sharma/AnushkaSharma4.wav\n",
      "Anushka_Sharma/AnushkaSharma5.wav\n",
      "+ modeling completed for speaker: Anushka_Sharma/AnushkaSharma5.wav.gmm  with data point =  (60028, 40)\n",
      "Aishwarya_Rai/AishwaryaRai1.wav\n",
      "Aishwarya_Rai/AishwaryaRai2.wav\n",
      "Aishwarya_Rai/AishwaryaRai3.wav\n",
      "Aishwarya_Rai/AishwaryaRai4.wav\n",
      "Aishwarya_Rai/AishwaryaRai5.wav\n",
      "+ modeling completed for speaker: Aishwarya_Rai/AishwaryaRai5.wav.gmm  with data point =  (60037, 40)\n",
      "Hrithik_Roshan/HrithikRoshan1.wav\n",
      "Hrithik_Roshan/HrithikRoshan2.wav\n",
      "Hrithik_Roshan/HrithikRoshan3.wav\n",
      "Hrithik_Roshan/HrithikRoshan4.wav\n",
      "Hrithik_Roshan/HrithikRoshan5.wav\n",
      "+ modeling completed for speaker: Hrithik_Roshan/HrithikRoshan5.wav.gmm  with data point =  (59836, 40)\n",
      "Aamir_Khan/AamirKhan1.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aamir_Khan/AamirKhan2.wav\n",
      "Aamir_Khan/AamirKhan3.wav\n",
      "Aamir_Khan/AamirKhan4.wav\n",
      "Aamir_Khan/AamirKhan5.wav\n",
      "+ modeling completed for speaker: Aamir_Khan/AamirKhan5.wav.gmm  with data point =  (60034, 40)\n",
      "Katrina_Kaif/KatrinaKaif1.wav\n",
      "Katrina_Kaif/KatrinaKaif2.wav\n",
      "Katrina_Kaif/KatrinaKaif3.wav\n",
      "Katrina_Kaif/KatrinaKaif4.wav\n",
      "Katrina_Kaif/KatrinaKaif5.wav\n",
      "+ modeling completed for speaker: Katrina_Kaif/KatrinaKaif5.wav.gmm  with data point =  (60034, 40)\n",
      "Priyanka_Chopra/PriyankaChopra1.wav\n",
      "Priyanka_Chopra/PriyankaChopra2.wav\n",
      "Priyanka_Chopra/PriyankaChopra3.wav\n",
      "Priyanka_Chopra/PriyankaChopra4.wav\n",
      "Priyanka_Chopra/PriyankaChopra5.wav\n",
      "+ modeling completed for speaker: Priyanka_Chopra/PriyankaChopra5.wav.gmm  with data point =  (60034, 40)\n",
      "Ranveer_Singh/RanveerSingh1.wav\n",
      "Ranveer_Singh/RanveerSingh2.wav\n",
      "Ranveer_Singh/RanveerSingh3.wav\n",
      "Ranveer_Singh/RanveerSingh4.wav\n",
      "Ranveer_Singh/RanveerSingh5.wav\n",
      "+ modeling completed for speaker: Ranveer_Singh/RanveerSingh5.wav.gmm  with data point =  (60034, 40)\n",
      "Rashmika_Mandana/RashmikaMandana1.wav\n",
      "Rashmika_Mandana/RashmikaMandana2.wav\n",
      "Rashmika_Mandana/RashmikaMandana3.wav\n",
      "Rashmika_Mandana/RashmikaMandana4.wav\n",
      "Rashmika_Mandana/RashmikaMandana5.wav\n",
      "+ modeling completed for speaker: Rashmika_Mandana/RashmikaMandana5.wav.gmm  with data point =  (60034, 40)\n",
      "Shahid_Kapoor/ShahidKapoor1.wav\n",
      "Shahid_Kapoor/ShahidKapoor2.wav\n",
      "Shahid_Kapoor/ShahidKapoor3.wav\n",
      "Shahid_Kapoor/ShahidKapoor4.wav\n",
      "Shahid_Kapoor/ShahidKapoor5.wav\n",
      "+ modeling completed for speaker: Shahid_Kapoor/ShahidKapoor5.wav.gmm  with data point =  (60034, 40)\n",
      "Shahrukh_Khan/ShahrukhKhan1.wav\n",
      "Shahrukh_Khan/ShahrukhKhan2.wav\n",
      "Shahrukh_Khan/ShahrukhKhan3.wav\n",
      "Shahrukh_Khan/ShahrukhKhan4.wav\n",
      "Shahrukh_Khan/ShahrukhKhan5.wav\n",
      "+ modeling completed for speaker: Shahrukh_Khan/ShahrukhKhan5.wav.gmm  with data point =  (60034, 40)\n",
      "Sonakshi_Sinha/SonakshiSinha1.wav\n",
      "Sonakshi_Sinha/SonakshiSinha2.wav\n",
      "Sonakshi_Sinha/SonakshiSinha3.wav\n",
      "Sonakshi_Sinha/SonakshiSinha4.wav\n",
      "Sonakshi_Sinha/SonakshiSinha5.wav\n",
      "+ modeling completed for speaker: Sonakshi_Sinha/SonakshiSinha5.wav.gmm  with data point =  (60034, 40)\n",
      "Sushant_Singh_Rajput/SushantSinghRajput1.wav\n",
      "Sushant_Singh_Rajput/SushantSinghRajput2.wav\n",
      "Sushant_Singh_Rajput/SushantSinghRajput3.wav\n",
      "Sushant_Singh_Rajput/SushantSinghRajput4.wav\n",
      "Sushant_Singh_Rajput/SushantSinghRajput5.wav\n",
      "+ modeling completed for speaker: Sushant_Singh_Rajput/SushantSinghRajput5.wav.gmm  with data point =  (60037, 40)\n",
      "Taapsee_Pannu/TaapseePannu1.wav\n",
      "Taapsee_Pannu/TaapseePannu2.wav\n",
      "Taapsee_Pannu/TaapseePannu3.wav\n",
      "Taapsee_Pannu/TaapseePannu4.wav\n",
      "Taapsee_Pannu/TaapseePannu5.wav\n",
      "+ modeling completed for speaker: Taapsee_Pannu/TaapseePannu5.wav.gmm  with data point =  (60037, 40)\n",
      "Vicky_Kaushal/VickyKaushal1.wav\n",
      "Vicky_Kaushal/VickyKaushal2.wav\n",
      "Vicky_Kaushal/VickyKaushal3.wav\n",
      "Vicky_Kaushal/VickyKaushal4.wav\n",
      "Vicky_Kaushal/VickyKaushal5.wav\n",
      "+ modeling completed for speaker: Vicky_Kaushal/VickyKaushal5.wav.gmm  with data point =  (60037, 40)\n",
      "\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'TestData/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-7bd2a71d07d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;31m# read the audio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0msr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maudio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;31m# extract 40 dimensional MFCC & delta MFCC features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\io\\wavfile.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(filename, mmap)\u001b[0m\n\u001b[0;32m    637\u001b[0m         \u001b[0mmmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 639\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'TestData/'"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import _pickle as cPickle\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import read\n",
    "from sklearn import mixture\n",
    "model = mixture.GaussianMixture(n_components=3, covariance_type='full',n_init = 3)\n",
    "import sklearn.feature_extraction\n",
    "#from speakerfeatures import extract_features\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#path to training data\n",
    "# source   = \"development_set/\"\n",
    "source   = \"TestData/\"   \n",
    "\n",
    "#path where training speakers will be saved\n",
    "\n",
    "# dest = \"speaker_models/\"\n",
    "# train_file = \"development_set_enroll.txt\"\n",
    "\n",
    "dest = \"Speakers_models/\"\n",
    "train_file = \"trainingDataPath.txt\"        \n",
    "file_paths = open(train_file,'r')\n",
    "\n",
    "count = 1\n",
    "# Extracting features for each speaker (5 files per speakers)\n",
    "features = np.asarray(())\n",
    "for path in file_paths:    \n",
    "    path = path.strip()   \n",
    "    print(path)\n",
    "    \n",
    "    # read the audio\n",
    "    sr,audio = read(source + path)\n",
    "    \n",
    "    # extract 40 dimensional MFCC & delta MFCC features\n",
    "    vector   = extract_features(audio,sr)\n",
    "    \n",
    "    if features.size == 0:\n",
    "        features = vector\n",
    "    else:\n",
    "        features = np.vstack((features, vector))\n",
    "    # when features of 5 files of speaker are concatenated, then do model training\n",
    "\t# -> if count == 5: --> edited below\n",
    "    if count == 5:    \n",
    "        gmm = model\n",
    "        gmm.fit(features)\n",
    "        \n",
    "        # dumping the trained gaussian model\n",
    "        picklefile = path.split(\"-\")[0]+\".gmm\"\n",
    "        cPickle.dump(gmm,open(dest + picklefile,'wb'))\n",
    "        print ('+ modeling completed for speaker:',picklefile,\" with data point = \",features.shape)    \n",
    "        features = np.asarray(())\n",
    "        count = 0\n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f32c771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccdc758d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to Test a Single Audio: Press '1' or The complete Test Audio Sample: Press '0' ?\n",
      "0\n",
      "Testing Audio :  Yuzi/Yuzi1.wav\n",
      "\tdetected as -  Yuzi5\n",
      "Testing Audio :  Aakash_chopra/Aakash_Chopra1.wav\n",
      "\tdetected as -  Aakash_Chopra5\n",
      "Testing Audio :  ABD/ABD5.wav\n",
      "\tdetected as -  AB_deviliers\n",
      "Testing Audio :  Ashwin/Ashwin4.wav\n",
      "\tdetected as -  Ravi_Ashwin\n",
      "Testing Audio :  Ben_stokes/Ben_stokes2.wav\n",
      "\tdetected as -  Ben_stokes5\n",
      "Testing Audio :  Bhuvi/Bhuvi4.wav\n",
      "\tdetected as -  Bhuvneshwar_kumar\n",
      "Testing Audio :  Bindra/Abhinav_Bindra3.wav\n",
      "\tdetected as -  Abhinav_Bindra\n",
      "Testing Audio :  Ganguly/Saurav_Ganguly5.wav\n",
      "\tdetected as -  Saurav_Ganguly5\n",
      "Testing Audio :  Kohli/Virat_kohli4.wav\n",
      "\tdetected as -  Virat_kohli\n",
      "Testing Audio :  Raina/Suresh_Raina5.wav\n",
      "\tdetected as -  Suresh_Raina5\n",
      "Testing Audio :  Sachin/Sachin4.wav\n",
      "\tdetected as -  Sachin5\n",
      "Testing Audio :  Tim_Paine/Tim_Paine5.wav\n",
      "\tdetected as -  Tim_Paine\n",
      "Testing Audio :  Tim_Paine/Tim_Paine2.wav\n",
      "\tdetected as -  Tim_Paine\n",
      "Testing Audio :  Bhuvi/Bhuvi1.wav\n",
      "\tdetected as -  Bhuvi5\n",
      "Testing Audio :  Deepika_Padukone/DeepikaPadukone2.wav\n",
      "\tdetected as -  DeepikaPadukone5\n",
      "Testing Audio :  Parineeti_Chopra/ParineetiChopra5.wav\n",
      "\tdetected as -  ParineetiChopra5\n",
      "Testing Audio :  Ayushmann_Khurrana/AyushmannKhurrana4.wav\n",
      "\tdetected as -  AyushmannKhurrana5\n",
      "Testing Audio :  Kriti_Sanon/KritiSanon2.wav\n",
      "\tdetected as -  KritiSanon5\n",
      "Testing Audio :  Kartik_Aaryan/KartikAaryan1.wav\n",
      "\tdetected as -  KartikAaryan5\n",
      "Testing Audio :  Akshay_Kumar/AkshayKumar4.wav\n",
      "\tdetected as -  AkshayKumar5\n",
      "Testing Audio :  Anushka_Sharma/AnushkaSharma2.wav\n",
      "\tdetected as -  AnushkaSharma5\n",
      "Testing Audio :  Aishwarya_Rai/AishwaryaRai5.wav\n",
      "\tdetected as -  AishwaryaRai5\n",
      "Testing Audio :  Hrithik_Roshan/HrithikRoshan3.wav\n",
      "\tdetected as -  HrithikRoshan5\n",
      "Testing Audio :  Aamir_Khan/AamirKhan1.wav\n",
      "\tdetected as -  AamirKhan5\n",
      "Testing Audio :  Katrina_Kaif/KatrinaKaif4.wav\n",
      "\tdetected as -  KatrinaKaif5\n",
      "Testing Audio :  Priyanka_Chopra/PriyankaChopra3.wav\n",
      "\tdetected as -  PriyankaChopra5\n",
      "Testing Audio :  Ranveer_Singh/RanveerSingh2.wav\n",
      "\tdetected as -  RanveerSingh5\n",
      "Testing Audio :  Rashmika_Mandana/RashmikaMandana1.wav\n",
      "\tdetected as -  RashmikaMandana5\n",
      "Testing Audio :  Shahid_Kapoor/ShahidKapoor3.wav\n",
      "\tdetected as -  ShahidKapoor5\n",
      "Testing Audio :  Shahrukh_Khan/ShahrukhKhan3.wav\n",
      "\tdetected as -  ShahrukhKhan5\n",
      "Testing Audio :  Sonakshi_Sinha/SonakshiSinha4.wav\n",
      "\tdetected as -  SonakshiSinha5\n",
      "Testing Audio :  Sushant_Singh_Rajput/SushantSinghRajput1.wav\n",
      "\tdetected as -  SushantSinghRajput5\n",
      "Testing Audio :  Taapsee_Pannu/TaapseePannu2.wav\n",
      "\tdetected as -  TaapseePannu5\n",
      "Testing Audio :  Vicky_Kaushal/VickyKaushal4.wav\n",
      "\tdetected as -  VickyKaushal5\n",
      "Testing Audio :  Aashna Hegde/AH2(2).wav\n",
      "\tdetected as -  Aashna Hegde\n",
      "Testing Audio :  Ashish/Ashish1(1).wav\n",
      "\tdetected as -  Ashish Chanchalani\n",
      "Testing Audio :  BB Ki Vines/BB3(1).wav\n",
      "\tdetected as -  Bhuvan Bham\n",
      "Testing Audio :  Beer Biceps/Beer2(2).wav\n",
      "\tdetected as -  Ranveer Allahbadia\n",
      "Testing Audio :  Carryminati/Carryminati2(1).wav\n",
      "\tdetected as -  Ajey Nagar\n",
      "Testing Audio :  Dhruv RATHEE/Dhruv3(1).wav\n",
      "\tdetected as -  Dhruv3(1)\n",
      "Testing Audio :  Flying Beast/FB1(2).wav\n",
      "\tdetected as -  Gaurav Taneja\n",
      "Testing Audio :  Harsh Beniwal/Harsh2(2).wav\n",
      "\tdetected as -  Harsh Beniwal\n",
      "Testing Audio :  Kabita/K2(1).wav\n",
      "\tdetected as -  K2(2)\n",
      "Testing Audio :  Kenny Sebastian/KS1(1).wav\n",
      "\tdetected as -  KS3(1)\n",
      "Testing Audio :  MostlySane/MS2(1).wav\n",
      "\tdetected as -  Prajakta Kholi\n",
      "Testing Audio :  Mr. Indian Hacker/IH1(2).wav\n",
      "\tdetected as -  Dilraj Singh\n",
      "Testing Audio :  Sandeep Maheshwari/SM3(1).wav\n",
      "\tdetected as -  SM3(1)\n",
      "Testing Audio :  Sejal Kumar/SK1(1).wav\n",
      "\tdetected as -  Sejal Kumar\n",
      "Testing Audio :  Shivani Bafna/SB1(2).wav\n",
      "\tdetected as -  Shivani Bafna\n",
      "Hurray ! Speaker identified. Mission Accomplished Successfully. \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import _pickle as cPickle\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import read\n",
    "import sklearn.feature_extraction \n",
    "#from speakerfeatures import extract_features\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "\n",
    "\"\"\"\n",
    "#path to training data\n",
    "source   = \"development_set/\"   \n",
    "modelpath = \"speaker_models/\"\n",
    "test_file = \"development_set_test.txt\"        \n",
    "file_paths = open(test_file,'r')\n",
    "\"\"\"\n",
    "#path to training data\n",
    "source   = \"TestData/\" \n",
    "\n",
    "#path where training speakers will be saved\n",
    "modelpath = \"Speakers_models/\"\n",
    "gmm_files=[]\n",
    "for fname in os.listdir(modelpath):\n",
    "    file=os.path.join(modelpath,fname)\n",
    "    file+=\"/\"\n",
    "    for j in os.listdir(file):\n",
    "        if(j.endswith('.gmm')):\n",
    "            gmm_files.append(os.path.join(file,j))\n",
    "#gmm_files = [os.path.join(modelpath,fname) for fname in \n",
    "              #os.listdir(modelpath) if fname.endswith('.gmm')]\n",
    "#Load the Gaussian gender Models\n",
    "models    = [cPickle.load(open(fname,'rb')) for fname in gmm_files]\n",
    "speakers   = [fname.split(\"/\")[-1].split(\".gmm\")[0] for fname \n",
    "              in gmm_files]\n",
    "\n",
    "error = 0\n",
    "total_sample = 0.0\n",
    "\n",
    "\n",
    "print (\"Do you want to Test a Single Audio: Press '1' or The complete Test Audio Sample: Press '0' ?\")\n",
    "take = int(input().strip())\n",
    "if take == 1:\n",
    "    print (\"Enter the File name from Test Audio Sample Collection :\")\n",
    "    path = input().strip()   \n",
    "    print (\"Testing Audio : \", path)\n",
    "    sr,audio = read(source + path)\n",
    "    vector   = extract_features(audio,sr)\n",
    "    log_likelihood = np.zeros(len(models))\n",
    "\n",
    "    for i in range(len(models)):\n",
    "        gmm    = models[i]  #checking with each model one by one\n",
    "        scores = np.array(gmm.score(vector))\n",
    "        log_likelihood[i] = scores.sum()\n",
    "    winner = np.argmax(log_likelihood)\n",
    "    print (\"\\tdetected as - \", speakers[winner])\n",
    "\n",
    "    time.sleep(1.0)\n",
    "elif take == 0:\n",
    "    test_file = \"testSamplePath.txt\"        \n",
    "    file_paths = open(test_file,'r')\n",
    "\n",
    "\n",
    "    # Read the test directory and get the list of test audio files \n",
    "    for path in file_paths:   \n",
    "        total_sample += 1.0\n",
    "        path = path.strip()   \n",
    "        print(\"Testing Audio : \",path)\n",
    "        sr,audio = read(source + path)\n",
    "        vector   = extract_features(audio,sr)\n",
    "\n",
    "        log_likelihood = np.zeros(len(models)) \n",
    "\n",
    "        for i in range(len(models)):\n",
    "            gmm    = models[i]  #checking with each model one by one\n",
    "            scores = np.array(gmm.score(vector))\n",
    "            log_likelihood[i] = scores.sum()\n",
    "        winner = np.argmax(log_likelihood)\n",
    "        print (\"\\tdetected as - \", speakers[winner][0:-4])\n",
    "\n",
    "        checker_name = path.split(\"_\")[0]\n",
    "        \n",
    "\n",
    "\n",
    "print (\"Hurray ! Speaker identified. Mission Accomplished Successfully. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb2c38e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3418f36a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
